{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kona-O/topiary/blob/main/seed_to_alignment_advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3764585",
      "metadata": {
        "id": "e3764585"
      },
      "source": [
        "# Seed to alignment pipeline\n",
        "\n",
        "The seed_to_alignment function takes a seed dataframe (see documentation), BLASTs to find sequence hits, performs quality control, lowers alignment redundancy in a taxonomically informed fashion, and generates an alignment. This notebook offers users the option to manipulate arguments fed into each step of this part of the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c6d2c9",
      "metadata": {
        "id": "61c6d2c9"
      },
      "outputs": [],
      "source": [
        "import topiary\n",
        "\n",
        "from topiary._private import installed\n",
        "from topiary._private import check\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import string\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first code block below initiates the entire seed_to_aligment pipeline with default parameters set. Users can change the parameters here. Alternatively, the following code blocks break this pipeline into its separate sections for manipulations at each step."
      ],
      "metadata": {
        "id": "p2ddUsDzeEx_"
      },
      "id": "p2ddUsDzeEx_"
    },
    {
      "cell_type": "code",
      "source": [
        "df = seed_to_alignment(seed_df,\n",
        "                      out_dir=None,\n",
        "                      seqs_per_column=1,\n",
        "                      max_seq_number=500,\n",
        "                      redundancy_cutoff=0.90,\n",
        "                      worst_align_drop_fx=0.1,\n",
        "                      sparse_column_cutoff=0.80,\n",
        "                      align_trim=(0.05,0.95),\n",
        "                      ncbi_blast_db=None,\n",
        "                      local_blast_db=None,\n",
        "                      blast_xml=None,\n",
        "                      move_mrca_up_by=2,\n",
        "                      local_recip_blast_db=None, \n",
        "                      min_call_prob=0.95,\n",
        "                      partition_temp=1,\n",
        "                      hitlist_size=5000,\n",
        "                      e_value_cutoff=0.001,\n",
        "                      gapcosts=(11,1),\n",
        "                      num_ncbi_blast_threads=1,\n",
        "                      num_local_blast_threads=-1,\n",
        "                      restart=False,\n",
        "                      overwrite=False,\n",
        "                      keep_recip_blast_xml=False,\n",
        "                      verbose=False)\n",
        "topiary.write_dataframe(df,\"alignment.csv\")"
      ],
      "metadata": {
        "id": "2ewW1JdYeCYN"
      },
      "id": "2ewW1JdYeCYN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "65d79ad2",
      "metadata": {
        "id": "65d79ad2"
      },
      "source": [
        "### Argument definitions and default parameters for reference: \n",
        "----------\n",
        "**seed_df** : *pandas.DataFrame or str*\n",
        "<br> Dataframe with at least four columns: name, species, sequence, and aliases. See documentation on seed dataframes for details.\n",
        "out_dir : str, optionaloutput directory. If not specified, create an output directory with the format \"seed_to_alignment_{randomletters}\".\n",
        "\n",
        "**seqs_per_column** : *float, default=1*\n",
        "<br> Aim to have this number of sequences per column in the key species sequences. (For example, if the key sequence is 100 amino acids long, seqs_per_column=1 would aim for 100 sequences; 2 would aim for 200 sequences).\n",
        "\n",
        "**max_seq_number** : *int, default=500*\n",
        "<br> Maximum number of sequences to get, regardless of seqs_per_column and key sequence length.\n",
        "\n",
        "**redundancy_cutoff** : *float, default=0.90*\n",
        "<br> Merge sequences from closely related species with sequence identity above cutoff.\n",
        "\n",
        "**worst_align_drop_fx** : *float, default=0.1*\n",
        "<br> After alignment, drop approximately this fraction of the sequences, selecting those that have long insertions and are missing chunks of sequences.\n",
        "\n",
        "**sparse_column_cutoff** : *float, default=0.80*\n",
        "<br> When checking alignment quality, a column is sparse if it has gaps in more than sparse_column_cutoff sequences.\n",
        "\n",
        "**align_trim** : *tuple, default=(0.05,0.95)*\n",
        "<br> When checking alignment quality, do not score the first and last parts of the alignment. Interpreted like a slice, but with percentages. (0.0,1.0) would not trim; (0.05,0,98) would trim the first 0.05 off the front and the last 0.02 off the back.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**ncbi_blast_db** : *str, optional*\n",
        "<br> NCBI blast database to use. (If ncbi_blast_db, local_blast_db and blast_xml are all None, ncbi_blast_db is automatically set to \"nr\").\n",
        "\n",
        "**local_blast_db** : *str, optional*\n",
        "<br> Local blast database to use.\n",
        "\n",
        "**blast_xml** : *str or list, optional*\n",
        "<br> Previously generated blast xml files to load. This argument can be:\n",
        "+ single xml file (str)\n",
        "+ list of xml files (list of str)\n",
        "+ directory (str). Code will grab all .xml files in the directory.\n",
        "<br>\n",
        "\n",
        "**move_mrca_up_by** : *int, default=2*\n",
        "<br> When inferring the phylogenetic context from the seed dataframe, get the most recent common ancestor of the seed species, then find the taxonomic rank \"move_mrca_up_by\" levels above that ancestor. For example, if the key species all come from marsupials (Theria) and move_mrca_up_by == 2, the context will be Amniota (Theria -> Mammalia -> Amniota).\n",
        "\n",
        "**local_recip_blast_db** : *str, optional*\n",
        "<br> Local blast database to use for reciprocal blast. If None, construct a reciprocal blast database by downloading the proteomes of the key species from the NCBI.\n",
        "\n",
        "**min_call_prob** : *float, default=0.95*\n",
        "<br> Hits from all paralogs that yield a regular expression match to one of the aliases from the seed dataframe are weighted by their relative blast bit scores. Each paralog is assigned a relative probability. This cutoff is the minimum probability the best paralog match must have to result in a paralog call. Value should be between 0 and 1 (not inclusive), where increasing min_call_prob increases the stringency.\n",
        "\n",
        "**partition_temp** : *float, default=1*\n",
        "<br> When calculating posterior probability of the reciprocal blast paralog call, use this for weighting: 2^(bit_score/partition_temp). partition_temp should be a float > 0. A higher value corresponds to a higher stringency. (The bit score difference between the best hit and the bit scores of other hits would have to be higher to be significant). This is a minium value. It may be adjusted automatically to avoid numerical problems in the calculation.\n",
        "<br>\n",
        "<br>\n",
        "**hitlist_size** : *int, default=5000*\n",
        "<br> Download only the top hitlist_size hits in initial blast.\n",
        "\n",
        "**e_value_cutoff** : *float, default=0.001*\n",
        "<br> Only take hits with e_value better than e_value_cutoff in initial blast\n",
        "gapcost : tuple, default=(11,1) BLAST gapcosts (length 2 tuple of ints) in initial blast\n",
        "num_ncbi_blast_threads : int, default=1 number of threads to use for NCBI blast. -1 means use all available. (Multithreading rarely speeds up remote BLAST).\n",
        "\n",
        "**num_local_blast_threads** : *int, default=-1*\n",
        "<br> Number of threads to use for local blast. -1 means all available.\n",
        "<br>\n",
        "<br>\n",
        "**restart** : *bool, default=False*\n",
        "<br> Restart job from where it stopped in output directory. incompatible with overwrite.\n",
        "\n",
        "**overwrite** : *bool, default=False*\n",
        "<br> Overwrite out_dir if it already exists. incompatible with restart.\n",
        "\n",
        "**keep_recip_blast_xml** : *bool, default=False*\n",
        "<br> Whether or not to keep raw blast xml output.\n",
        "\n",
        "**verbose** : *bool, default=False*\n",
        "<br> Verbosity of output.\n",
        "<br>\n",
        "<br>\n",
        "Returns\n",
        "----------\n",
        "**topiary_dataframe** : *pandas.DataFrame*\n",
        "<br> Topiary dataframe with aligned, quality-controlled sequences.\n",
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "080fe002",
      "metadata": {
        "id": "080fe002"
      },
      "source": [
        "# 00. Build initial topiary dataframe\n",
        "\n",
        "First, we create an initial dataset of sequences by BLASTing sequences from the seed dataframe against the NCBI non-redundant protein sequence database or a database of the user's choice. The taxonomic scope is given by the taxonomic rank that encompasses the key species from the seed dataset, plus a user-defined expansion (set to 2 by default). By default, topiary pulls down up to 5,000 hits per seed with an intentionally generous e-value cutoff of 0.001. (Users have full control over the BLAST search parameters.)\n",
        "\n",
        "### The arguments provided in the \"kwargs\" dictionary for this call are:\n",
        "+ **seed_df** : *pandas.DataFrame or str* \n",
        "<br> Dataframe with at least four columns: name, species, sequence,and aliases. See documentation on seed dataframes for details.\n",
        "+ **ncbi_blast_db** : *str, optional*\n",
        "<br> NCBI blast database to use. (If ncbi_blast_db, local_blast_db and blast_xml are all None, ncbi_blast_db is automatically set to \"nr\").\n",
        "+ **local_blast_db** : *str, optional* \n",
        "<br> Local blast database to use.\n",
        "+ **blast_xml** : *str or list, optional*\n",
        "<br> Previously generated blast xml files to load. This argument can be:\n",
        "     + single xml file (str)\n",
        "     + list of xml files (list of str)\n",
        "     + directory (str). Code will grab all .xml files in the directory.\n",
        "+ **move_mrca_up_by** : *int, default=2*\n",
        "<br> When inferring the phylogenetic context from the seed dataframe, get the most recent common ancestor of the seed species, then find the taxonomic rank \"move_mrca_up_by\" levels above that ancestor. For example, if the key species all come from marsupials (Theria) and move_mrca_up_by == 2, the context will be Amniota (Theria -> Mammalia -> Amniota).\n",
        "+ **hitlist_size** : *int, default=5000*\n",
        "<br> Download only the top hitlist_size hits in initial blast.\n",
        "+ **e_value_cutoff** : *float, default=0.001*\n",
        "<br> Only take hits with e_value better than e_value_cutoff in initial blast.\n",
        "+ **gapcost** : *tuple, default=(11,1)*\n",
        "<br> BLAST gapcosts (length 2 tuple of ints) in initial blast.\n",
        "+ **num_ncbi_blast_threads** : *int, default=1*\n",
        "<br> Number of threads to use for NCBI blast. -1 means use all available. (Multithreading rarely speeds up remote BLAST).\n",
        "+ **num_local_blast_threads** : *int, default=-1*\n",
        "<br> Number of threads to use for local blast. -1 means all available.\n",
        "+ **keep_blast_xml** : *bool, default=True*     **--not in code definition?**\n",
        "<br> Whether or not to keep raw blast xml output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "068d5baf",
      "metadata": {
        "id": "068d5baf"
      },
      "outputs": [],
      "source": [
        "kwargs = {\"seed_df\":seed_df,\n",
        "          \"ncbi_blast_db\":ncbi_blast_db,\n",
        "          \"local_blast_db\":local_blast_db,\n",
        "          \"blast_xml\":blast_xml,\n",
        "          \"move_mrca_up_by\":move_mrca_up_by,\n",
        "          \"hitlist_size\":hitlist_size,\n",
        "          \"e_value_cutoff\":e_value_cutoff,\n",
        "          \"gapcosts\":gapcosts,\n",
        "          \"num_ncbi_blast_threads\":num_ncbi_blast_threads,\n",
        "          \"num_local_blast_threads\":num_local_blast_threads,\n",
        "          \"keep_blast_xml\":True}\n",
        "\n",
        "df, key_species, paralog_patterns = topiary.df_from_seed(**kwargs)\n",
        "topiary.write_dataframe(df,\"00_initial-dataframe.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cd90873",
      "metadata": {
        "id": "8cd90873"
      },
      "source": [
        "# 01. Reciprocal BLAST\n",
        "\n",
        "Once the initial dataset is constructed, topiary identifies each hit by reciprocal BLAST. It downloads proteomes for the key species in the seed dataset and constructs a combined local BLAST database. It then uses the hits above as queries against the key species BLAST database, searching the resulting reciprocal hits for text descriptions that match the aliases specified in the seed dataset. (See Protocol for details about defining aliases). It weights each hit by 2s/t where s is the BLAST bit score, and t is a user-defined parameter (default = 1). Finally, topiary calculates the posterior probability that the sequence is a given paralog by calculating the sum of the weights for all reciprocal hits that match a paralog alias and then dividing by the sum of the weights from all reciprocal hits. ## ***A sequence is assigned a paralog identity based on a user-defined stringency cutoff (default = 0.95).*** Multiple paralogs may be assigned if the sum of their posterior probabilities is above the cutoff. If the sequence does not pull up a hit in this reciprocal BLAST step, it will be removed from future steps of the pipeline.\n",
        "<br>\n",
        "<br>\n",
        "### Arguments used in this call are:\n",
        "+ **df** : *df*\n",
        "<br> Your input dataframe or dataset.\n",
        "+ **paralog_patterns = paralog_patterns**\n",
        "<br> XX_not exactly sure what this is... a column that should be in the dataframe?\n",
        "+ **local_blast_db = local_recip_blast_db** : *str, optional*\n",
        "<br> Local blast database to use for reciprocal blast. If None, construct a reciprocal blast database by downloading the proteomes of the key species from the ncbi.\n",
        "+ **num_threads = num_local_blast_threads** : *int, default=-1*\n",
        "<br> Number of threads to use for local blast. -1 means all available.\n",
        "+ **keep_blast_xml = keep_recip_blast_xml** : *bool, default=False*\n",
        "<br> Whether or not to keep raw blast xml output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cf78864",
      "metadata": {
        "id": "0cf78864"
      },
      "outputs": [],
      "source": [
        "df = topiary.recip_blast(df,\n",
        "                        paralog_patterns=paralog_patterns,\n",
        "                        local_blast_db=local_recip_blast_db,\n",
        "                        num_threads=num_local_blast_threads,\n",
        "                        keep_blast_xml=keep_recip_blast_xml)\n",
        "\n",
        "topiary.write_dataframe(df,\"01_recip-blast-dataframe.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c12272",
      "metadata": {
        "id": "53c12272"
      },
      "source": [
        "# 02. Reduce number of sequences\n",
        "\n",
        "This BLAST approach typically finds many more sequences than are necessary or practical for a standard phylogenetic analysis. We must therefore select sequences that sample the diversity in the dataset without compromising our ability to infer ancestors. Topiary selects a subset of sequences using a combination of taxonomy, sequence identity, and sequence quality. By default, topiary aims to build an alignment with approximately one sequence per site in the average length of seed sequences. If our seed sequences were 100 amino acids long, topiary would try to build an alignment with 100 sequences. This prevents over-fitting and makes later computational steps faster. (Users can change the target alignment size if desired).\n",
        "Topiary uses four strategies (outlined in detail in the documentation) to decrease the size of the dataset while maintaining dataset quality. First, sequences defined in the initial seed dataset are kept, regardless of their quality score or redundancy. Second, topiary selects sequences based on their placement on the species tree rather than solely based on their identity. Third, when merging blocks of similar sequences, topiary preferentially keeps sequences that align well to the seed sequences. Fourth and finally, there are a few steps where topiary lowers redundancy based on shared sequence identity.\n",
        "\n",
        "The full quality control and redundancy reduction steps incorporating the strategies summarized above are as follows. All parameters have useful default values but can be adjusted by users.\n",
        "1. Remove sequences from species that cannot be resolved on the most recent Open Tree of Life synthetic tree.\n",
        "2. Discard sequences that do not return a seed sequence when used as reciprocal BLAST queries against proteomes from key species.\n",
        "3. Remove similar sequences within each species using a sequence identity cutoff (default = 0.90). This removes isoforms and recent lineage-specific duplications.\n",
        "4. Remove similar sequences taken from closely related species using a sequence identity cutoff (default = 0.90).\n",
        "5. Calculate a target alignment size based on the average length of the seed sequences (typically one sequence per amino acid in the average seed length). Then multiply this by 1.1 so we can remove sequences after budgeting and still have an alignment of the desired size.\n",
        "6. Using the species tree, identify blocks of sequences from closely related species using the budgeting strategy seen in Figure 4. Generate an MSA for the sequences in the block plus the seed sequences, and then select the best-aligning sequence within each block.\n",
        "7. Align all sequences in the current dataset, which will have ~1.1 times the target alignment size. Remove the worst aligning sequences.\n",
        "a. Remove the sequences with the most characters in non-dense columns (drop worst 2.5%).\n",
        "b. Remove the sequences with the most missing dense columns (drop worst 2.5%).\n",
        "\n",
        "This yields a relatively clean dataset with ~5% more sequences than our target alignment number. We leave these extra sequences in place so we can manually delete the worst aligners upon visual inspection and still have our approximate target number of sequences.\n",
        "<br>\n",
        "<br>\n",
        "### Arguments used in this call are:\n",
        "\n",
        "+ **df** : *df*\n",
        "<br> Your input dataframe or dataset.\n",
        "+ **paralog_column** : *recip_paralog*\n",
        "<br> XX_not exactly sure what this is... a column that should be in the dataframe?\n",
        "+ **seqs_per_column** : *float, default=1*\n",
        "<br> Aim to have this number of sequences per column in the key species sequences. (For example, if the key sequence is 100 amino acids long,\n",
        "seqs_per_column=1 would aim for 100 sequences; 2 would aim for 200 sequences).\n",
        "+ **worst_align_drop_fx** : *float, default=0.1*\n",
        "<br> After alignment, drop approximately this fraction of the sequences, selecting those that have long insertions and are missing chunks of sequences.\n",
        "+ **max_seq_number** : *int, default=500*\n",
        "<br> Maximum number of sequences to get, regardless of seqs_per_column and key sequence length. \n",
        "+ **redundancy_cutoff** : *float, default=0.90* \n",
        "<br> Merge sequences from closely related species with sequence identity above cutoff.\n",
        "+ **sparse_column_cutoff** : *float, default=0.80*\n",
        "<br> When checking alignment quality, a column is sparse if it has gaps in more than sparse_column_cutoff sequences.\n",
        "+ **align_trim** : *tuple, default=(0.05,0.95)*\n",
        "<br> When checking alignment quality, do not score the first and last parts of the alignment. Interpreted like a slice, but with percentages (0.0,1.0) would not trim; (0.05,0,98) would trim the first 0.05 off the front and the last 0.02 off the back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47af8875",
      "metadata": {
        "id": "47af8875"
      },
      "outputs": [],
      "source": [
        "kwargs = {\"df\":df,\n",
        "          \"paralog_column\":\"recip_paralog\",\n",
        "          \"seqs_per_column\":seqs_per_column*(1 + worst_align_drop_fx),\n",
        "          \"max_seq_number\":max_seq_number*(1 + worst_align_drop_fx),\n",
        "          \"redundancy_cutoff\":redundancy_cutoff,\n",
        "          \"sparse_column_cutoff\":sparse_column_cutoff,\n",
        "          \"align_trim\":align_trim}\n",
        "\n",
        "df = topiary.quality.shrink_dataset(**kwargs)\n",
        "topiary.write_dataframe(df,\"02_shrunk-dataframe.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c82aae8",
      "metadata": {
        "id": "6c82aae8"
      },
      "source": [
        "# 03. Align sequences\n",
        "\n",
        "Topiary uses Muscle5 with its default parameters to generate the MSA. We\n",
        "selected this algorithm due to its demonstrated high performance, as well as the extremely fast “super5” algorithm that is useful for generating draft alignments for large datasets. Advanced users can set all Muscle5 options. ***XXX is that going to be written out here? XXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e939721",
      "metadata": {
        "id": "6e939721"
      },
      "outputs": [],
      "source": [
        "df = topiary.muscle.align(df)\n",
        "topiary.write_dataframe(df,\"03_clean-aligned-dataframe.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb9ee54a",
      "metadata": {
        "id": "fb9ee54a"
      },
      "source": [
        "# 04-05. Polish alignment and re-align\n",
        "\n",
        "### Arguments used in this call:\n",
        "\n",
        "+ **df** : *df*\n",
        "<br> Your input dataframe or dataset.\n",
        "+ **worst_align_drop_fx** : *float, default=0.1*\n",
        "<br> After alignment, drop approximately this fraction of the sequences, selecting those that have long insertions and are missing chunks of sequences.\n",
        "+ **fx_sparse_percential** : *(1 - worst_align_drop_fx)* XX\n",
        "+ **sparse_run_percentile** : *(1 - worst_align_drop_fx)* XX\n",
        "+ **fx_missing_percentile** : *(1 - worst_align_drop_fx)* XX\n",
        "+ **realign** : *bool, default=True*\n",
        "<br> Re-align the MSA if set to True.\n",
        "+ **sparse_column_cutoff** : *float, default=0.80*\n",
        "<br> When checking alignment quality, a column is sparse if it has gaps in more than sparse_column_cutoff sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79cb0dd",
      "metadata": {
        "id": "d79cb0dd"
      },
      "outputs": [],
      "source": [
        "kwargs = {\"df\":df,\n",
        "          \"fx_sparse_percential\":(1 - worst_align_drop_fx),\n",
        "          \"sparse_run_percentile\":(1 - worst_align_drop_fx),\n",
        "          \"fx_missing_percentile\":(1 - worst_align_drop_fx),\n",
        "          \"realign\":True,\n",
        "          \"sparse_column_cutoff\":sparse_column_cutoff}\n",
        "\n",
        "df = topiary.quality.polish_alignment(**kwargs)\n",
        "topiary.write_dataframe(df,\"04_clean-aligned-dataframe.csv\")\n",
        "topiary.write_fasta(df,\n",
        "                    f\"{step_counter:02d}_alignment.fasta\",\n",
        "                    seq_column=\"alignment\",\n",
        "                    label_columns=[\"species\",\"recip_paralog\"])\n",
        "\n",
        "os.chdir(cwd)\n",
        "\n",
        "pretty_name = os.path.join(out_dir,\"05_clean-aligned-dataframe.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}